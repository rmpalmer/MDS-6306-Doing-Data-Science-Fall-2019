---
title: "Unit7 PreLive"
author: "Richard Palmer"
date: "10/8/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# get libraries
library(dplyr)
library(ggplot2)
library(tidyverse)
library(stringr)
library(caret)
library(class)
library(XML) #xml_Parse
library(RCurl) #getURL
library(jsonlite)
library(rvest)

```

# Part 1

## Get the data 
```{r}
passengers_url <- "https://public.opendatasoft.com/api/records/1.0/search/?dataset=titanic-passengers&rows=2000&facet=survived&facet=pclass&facet=sex&facet=age&facet=embarked"
passenger_json <- jsonlite::fromJSON(passengers_url,flatten=TRUE)
passenger_df <- passenger_json$records
titanicClean <- passenger_df %>% select(fields.age,fields.pclass,fields.survived,fields.sex) %>%
  mutate(Sex = as.factor(fields.sex)) %>% 
  select(-fields.sex) %>%
  dplyr::rename(Age=fields.age,Pclass=fields.pclass,Survived=fields.survived) %>%
  select(Age,Pclass,Sex,Survived) %>%
  drop_na()
```

## first model

use all valid observations and predict survival for 30 year old in each class
```{r}
model_a = naiveBayes(titanicClean[,c(1,2)],titanicClean$Survived)
predict(model_a,cbind(Age=30,Pclass=c(1,2,3)), type = "raw")
```

split into train and test datasets
```{r}
set.seed(4)
trainIndices = sample(seq(1:length(titanicClean$Age)),round(.7*length(titanicClean$Age)))
trainTitanic = titanicClean[trainIndices,]
testTitanic = titanicClean[-trainIndices,]
head(trainTitanic)
head(testTitanic)
```

```{r}
model_b <-  naiveBayes(trainTitanic[,c(1,2)],trainTitanic$Survived)
result_b <- predict(model_b,testTitanic[,c(1,2)])
result_x <- predict(model_b,testTitanic[,c(1,2)], type = "raw")
CM = confusionMatrix(result_x,testTitanic$Survived)
```

KNN classifier results
```{r}
knn_pred_titanic <- knn(trainTitanic[,1:2],testTitanic[,1:2],trainTitanic$Survived,k=3,prob=TRUE)
CM_knn_titanic   <- confusionMatrix(knn_pred_titanic,testTitanic$Survived)
```

Now add sex to the model
```{r}
model_c = naiveBayes(titanicClean[,c(1,2,3)],titanicClean$Survived)
```

# Part 2

Naive Bayes for multinomial iris
```{r}

iterations = 100

masterAccNB = matrix(nrow = iterations)

splitPerc = .7 #Training / Test split Percentage

for(j in 1:iterations)
{
  
  trainIndices = sample(1:dim(iris)[1],round(splitPerc * dim(iris)[1]))
  train = iris[trainIndices,]
  test = iris[-trainIndices,]
  
  model = naiveBayes(train[,c(1,2)],as.factor(train$Species),laplace = 1)
  table(predict(model,test[,c(1,2)]),as.factor(test$Species))
  CM = confusionMatrix(table(predict(model,test[,c(1,2)]),as.factor(test$Species)))
  masterAccNB[j] = CM$overall[1]
}

MeanAccNB = colMeans(masterAccNB)

MeanAccNB

```

KNN for multinomial iris
```{r}
# from Unit 6, peak accuracy was with k = 33
my_k = 33
acc_knn = matrix(nrow=iterations,ncol=1)
for (j in 1:iterations)
{
  trainIndices = sample(1:dim(iris)[1],round(splitPerc * dim(iris)[1]))
  train = of_interest[trainIndices,]
  test  = of_interest[-trainIndices,]
  classifications <- knn(train[,1:2],test[1:2],train[,3],k=my_k)
  cm = confusionMatrix(classifications,test$Species)
  acc_knn[j,1] = cm$overall[1]
}
MeanAccKnn = colMeans(acc_knn)

MeanAccKnn
```









